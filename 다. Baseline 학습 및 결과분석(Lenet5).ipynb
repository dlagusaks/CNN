{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf8e9c4",
   "metadata": {
    "id": "5cf8e9c4",
    "outputId": "cb68cb3c-f28c-4bf4-8fa9-acbe96cea74e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LG\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.12.0\n",
      "No GPU was detected. CNNs can be very slow without a GPU.\n",
      "GPU installed:  False\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "print(\"TF version: \", tf.__version__)\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# GPU test\n",
    "print(\"GPU installed: \",tf.test.is_built_with_gpu_support())\n",
    "\n",
    "# To prevent \"CUDNN_STATUS_ALLOC_FAILED\" error with GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165a73a",
   "metadata": {},
   "source": [
    "# 다. Baseline 학습 및 결과분석(Lenet5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e6ea5",
   "metadata": {},
   "source": [
    "### 나) 부분에 생성된 데이터가 있다면 전체 다 실행 할 필요 없으나\n",
    "### 생성된 데이터가 없고 파일 다) 만 있다는 가정하에 초반부에 나)의 내용도 포함시켜음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b3e416",
   "metadata": {
    "id": "65b3e416"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.layers import BatchNormalization, GlobalAveragePooling2D, MaxPooling2D, Add,  Dense, Conv2D, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e130cbf0",
   "metadata": {
    "id": "e130cbf0"
   },
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('emnist-byclass-train.csv',header=None)\n",
    "X_test=pd.read_csv('emnist-byclass-test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e5f2ee",
   "metadata": {
    "id": "a5e5f2ee"
   },
   "outputs": [],
   "source": [
    "def data_split(data_type_train,split_ratio=0.1):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=split_ratio, random_state=42)\n",
    "    for train_idx, test_idx in split.split(data_type_train, data_type_train[0]):\n",
    "        x_train = data_type_train.loc[train_idx]\n",
    "        x_valid = data_type_train.loc[test_idx]\n",
    "    return x_train,x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4927cb9",
   "metadata": {
    "id": "f4927cb9"
   },
   "outputs": [],
   "source": [
    "def data_load(data_type_train,data_type_valid,data_type_test):\n",
    "    x_train =data_type_train.iloc[:, 1:].values\n",
    "    y_train = data_type_train.iloc[:, 0].values\n",
    "    x_valid =data_type_valid.iloc[:, 1:].values\n",
    "    y_valid = data_type_valid.iloc[:, 0].values\n",
    "    x_test = data_type_test.iloc[:, 1:].values\n",
    "    y_test = data_type_test.iloc[:, 0].values\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    return x_train,y_train,x_valid,y_valid,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18de3b1",
   "metadata": {
    "id": "c18de3b1"
   },
   "outputs": [],
   "source": [
    "X_train,X_valid=data_split(X_train,0.235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66308599",
   "metadata": {
    "id": "66308599"
   },
   "outputs": [],
   "source": [
    "X_train,y_train,X_valid,y_valid,X_test,y_test=data_load(X_train,X_valid,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6b82e",
   "metadata": {
    "id": "63d6b82e"
   },
   "outputs": [],
   "source": [
    "np.save('X_train',np.array(X_train,dtype=np.uint8))\n",
    "np.save('y_train',np.array(y_train,dtype=np.uint8))\n",
    "np.save('X_valid',np.array(X_valid,dtype=np.uint8))\n",
    "np.save('y_valid',np.array(y_valid,dtype=np.uint8))\n",
    "np.save('X_test',np.array(X_test,dtype=np.uint8))\n",
    "np.save('y_test',np.array(y_test,dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d7544",
   "metadata": {
    "id": "dd9d7544"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def load_Emist():\n",
    "    X_train=np.load('X_train.npy')\n",
    "    y_train=np.load('y_train.npy')\n",
    "    X_valid=np.load('X_valid.npy')\n",
    "    y_valid=np.load('y_valid.npy')\n",
    "    X_test=np.load('X_test.npy')\n",
    "    y_test=np.load('y_test.npy')\n",
    "    return X_train, y_train, X_valid, y_valid, X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7a222",
   "metadata": {
    "id": "96e7a222",
    "outputId": "aa82a1e9-32f4-43d7-cc48-fd9d1f0657da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((533917, 28, 28, 1), dtype('uint8'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_Emist()\n",
    "X_train.shape,X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff3efe",
   "metadata": {
    "id": "deff3efe"
   },
   "outputs": [],
   "source": [
    "#data, batch size 성정\n",
    "train_size=len(X_train)\n",
    "valid_size=len(X_valid)\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d52450",
   "metadata": {
    "id": "f6d52450"
   },
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train,[-1,784])\n",
    "X_valid=np.reshape(X_valid,[-1,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966754fe",
   "metadata": {
    "id": "966754fe"
   },
   "outputs": [],
   "source": [
    "y_train=np.reshape(y_train,[-1,1])\n",
    "y_valid=np.reshape(y_valid,[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d51ce",
   "metadata": {
    "id": "813d51ce"
   },
   "outputs": [],
   "source": [
    "train_full = np.append(X_train,y_train,axis=1)\n",
    "valid_full = np.append(X_valid,y_valid,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf3347",
   "metadata": {
    "id": "cbbf3347"
   },
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    \n",
    "    Emnist_dir = os.path.join(\"datasets\", \"Emnist\")\n",
    "    os.makedirs(Emnist_dir, exist_ok=True)\n",
    "    path_format = os.path.join(Emnist_dir, \"my_{}_{:02d}.csv\")\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        try:\n",
    "            with open(part_csv, \"xt\", encoding=\"utf-8\") as f:\n",
    "                if header is not None:\n",
    "                    f.write(header)\n",
    "                    f.write(\"\\n\")\n",
    "                for row_idx in row_indices:\n",
    "                    f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                    f.write(\"\\n\")\n",
    "        except:\n",
    "            continue\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b2cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = save_to_multiple_csv_files(train_full, \"train\")\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_full, \"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8de6f",
   "metadata": {},
   "source": [
    "### 나)에서  언급한대로 Lenet5에 맞는 preprocess로 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24758eb7",
   "metadata": {
    "id": "24758eb7"
   },
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[-1]\n",
    "def preprocess_Lenet(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    resized_image = tf.image.resize(x, [32, 32])\n",
    "    final_image = resized_image/255.\n",
    "    \n",
    "    return final_image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc4abd7",
   "metadata": {
    "id": "abc4abd7"
   },
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess_Lenet, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d827ea",
   "metadata": {
    "id": "65d827ea"
   },
   "outputs": [],
   "source": [
    "train_set = csv_reader_dataset(train_filepaths,batch_size=batch_size, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths,batch_size=batch_size, repeat=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebc221",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da90c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####LENET-5 정의\n",
    "from tensorflow.keras import layers, models\n",
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(32,32,1)))\n",
    "model3.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model3.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "model3.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(120, activation='relu'))\n",
    "model3.add(layers.Dense(84, activation='relu'))\n",
    "model3.add(layers.Dense(62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6fe93f",
   "metadata": {},
   "source": [
    "### adamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79605bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(patience = 10)\n",
    "data_name=\"byclass\"\n",
    "type_name=\"LN5\"\n",
    "checkpoint_callback = ModelCheckpoint(data_name+\"_\"+type_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate=0.001,\n",
    "                                 beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model3.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "history3=model3.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size), \n",
    "                    epochs=1000,\n",
    "                    callbacks=[early_stopping, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37e54f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.5777 - accuracy: 0.8077\n",
      "Epoch 1: val_loss improved from inf to 0.45623, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 134s 8ms/step - loss: 0.5776 - accuracy: 0.8077 - val_loss: 0.4562 - val_accuracy: 0.8379\n",
      "Epoch 2/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.4259 - accuracy: 0.8468\n",
      "Epoch 2: val_loss improved from 0.45623 to 0.41630, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 123s 7ms/step - loss: 0.4259 - accuracy: 0.8468 - val_loss: 0.4163 - val_accuracy: 0.8510\n",
      "Epoch 3/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3995 - accuracy: 0.8544\n",
      "Epoch 3: val_loss improved from 0.41630 to 0.41325, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3996 - accuracy: 0.8544 - val_loss: 0.4133 - val_accuracy: 0.8513\n",
      "Epoch 4/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3918 - accuracy: 0.8561\n",
      "Epoch 4: val_loss improved from 0.41325 to 0.39889, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3918 - accuracy: 0.8561 - val_loss: 0.3989 - val_accuracy: 0.8538\n",
      "Epoch 5/1000\n",
      "16675/16684 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8592\n",
      "Epoch 5: val_loss improved from 0.39889 to 0.39835, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 105s 6ms/step - loss: 0.3815 - accuracy: 0.8592 - val_loss: 0.3983 - val_accuracy: 0.8547\n",
      "Epoch 6/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3721 - accuracy: 0.8612\n",
      "Epoch 6: val_loss improved from 0.39835 to 0.39834, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 102s 6ms/step - loss: 0.3721 - accuracy: 0.8612 - val_loss: 0.3983 - val_accuracy: 0.8561\n",
      "Epoch 7/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.8623\n",
      "Epoch 7: val_loss improved from 0.39834 to 0.38756, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 104s 6ms/step - loss: 0.3709 - accuracy: 0.8623 - val_loss: 0.3876 - val_accuracy: 0.8590\n",
      "Epoch 8/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.8620\n",
      "Epoch 8: val_loss did not improve from 0.38756\n",
      "16684/16684 [==============================] - 104s 6ms/step - loss: 0.3695 - accuracy: 0.8620 - val_loss: 0.3907 - val_accuracy: 0.8567\n",
      "Epoch 9/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.8633\n",
      "Epoch 9: val_loss improved from 0.38756 to 0.38511, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3656 - accuracy: 0.8633 - val_loss: 0.3851 - val_accuracy: 0.8598\n",
      "Epoch 10/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3511 - accuracy: 0.8669\n",
      "Epoch 10: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3511 - accuracy: 0.8669 - val_loss: 0.3942 - val_accuracy: 0.8586\n",
      "Epoch 11/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3629 - accuracy: 0.8639\n",
      "Epoch 11: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3628 - accuracy: 0.8639 - val_loss: 0.3904 - val_accuracy: 0.8586\n",
      "Epoch 12/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.8651\n",
      "Epoch 12: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3592 - accuracy: 0.8651 - val_loss: 0.3873 - val_accuracy: 0.8589\n",
      "Epoch 13/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3600 - accuracy: 0.8646\n",
      "Epoch 13: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3601 - accuracy: 0.8646 - val_loss: 0.3925 - val_accuracy: 0.8577\n",
      "Epoch 14/1000\n",
      "16675/16684 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.8675\n",
      "Epoch 14: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3510 - accuracy: 0.8675 - val_loss: 0.3949 - val_accuracy: 0.8581\n",
      "Epoch 15/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8665\n",
      "Epoch 15: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3532 - accuracy: 0.8665 - val_loss: 0.3862 - val_accuracy: 0.8582\n",
      "Epoch 16/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3546 - accuracy: 0.8663\n",
      "Epoch 16: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3546 - accuracy: 0.8663 - val_loss: 0.3913 - val_accuracy: 0.8567\n",
      "Epoch 17/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3558 - accuracy: 0.8657\n",
      "Epoch 17: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 102s 6ms/step - loss: 0.3558 - accuracy: 0.8657 - val_loss: 0.3895 - val_accuracy: 0.8576\n",
      "Epoch 18/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3495 - accuracy: 0.8678\n",
      "Epoch 18: val_loss improved from 0.38511 to 0.38315, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 104s 6ms/step - loss: 0.3495 - accuracy: 0.8678 - val_loss: 0.3832 - val_accuracy: 0.8600\n",
      "Epoch 19/1000\n",
      "16674/16684 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.8685\n",
      "Epoch 19: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3477 - accuracy: 0.8685 - val_loss: 0.3910 - val_accuracy: 0.8582\n",
      "Epoch 20/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8679\n",
      "Epoch 20: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 104s 6ms/step - loss: 0.3488 - accuracy: 0.8679 - val_loss: 0.3848 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3518 - accuracy: 0.8673\n",
      "Epoch 21: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 134s 8ms/step - loss: 0.3518 - accuracy: 0.8673 - val_loss: 0.3873 - val_accuracy: 0.8580\n",
      "Epoch 22/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.8683\n",
      "Epoch 22: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3482 - accuracy: 0.8683 - val_loss: 0.3840 - val_accuracy: 0.8605\n",
      "Epoch 23/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3467 - accuracy: 0.8688\n",
      "Epoch 23: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 137s 8ms/step - loss: 0.3468 - accuracy: 0.8688 - val_loss: 0.3900 - val_accuracy: 0.8573\n",
      "Epoch 24/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3495 - accuracy: 0.8678\n",
      "Epoch 24: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3495 - accuracy: 0.8678 - val_loss: 0.3872 - val_accuracy: 0.8598\n",
      "Epoch 25/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3489 - accuracy: 0.8680\n",
      "Epoch 25: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 137s 8ms/step - loss: 0.3489 - accuracy: 0.8680 - val_loss: 0.3850 - val_accuracy: 0.8598\n",
      "Epoch 26/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3440 - accuracy: 0.8694\n",
      "Epoch 26: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 135s 8ms/step - loss: 0.3440 - accuracy: 0.8694 - val_loss: 0.3910 - val_accuracy: 0.8576\n",
      "Epoch 27/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3424 - accuracy: 0.8697\n",
      "Epoch 27: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3424 - accuracy: 0.8697 - val_loss: 0.3864 - val_accuracy: 0.8595\n",
      "Epoch 28/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3450 - accuracy: 0.8690\n",
      "Epoch 28: val_loss did not improve from 0.38315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3450 - accuracy: 0.8690 - val_loss: 0.3858 - val_accuracy: 0.8590\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience = 10)\n",
    "data_name=\"byclass\"\n",
    "type_name=\"LN5\"\n",
    "checkpoint_callback = ModelCheckpoint(data_name+\"_\"+type_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate=0.001,\n",
    "                                 beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model3.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "history3=model3.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size), \n",
    "                    epochs=1000,\n",
    "                    callbacks=[early_stopping, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9ccd98",
   "metadata": {},
   "source": [
    "### nesteroV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a2cc308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.8855 - accuracy: 0.7368\n",
      "Epoch 1: val_loss improved from inf to 0.57336, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.8854 - accuracy: 0.7368 - val_loss: 0.5734 - val_accuracy: 0.8080\n",
      "Epoch 2/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.5216 - accuracy: 0.8220\n",
      "Epoch 2: val_loss improved from 0.57336 to 0.50539, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.5216 - accuracy: 0.8220 - val_loss: 0.5054 - val_accuracy: 0.8243\n",
      "Epoch 3/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.4761 - accuracy: 0.8338\n",
      "Epoch 3: val_loss improved from 0.50539 to 0.46884, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.4762 - accuracy: 0.8338 - val_loss: 0.4688 - val_accuracy: 0.8362\n",
      "Epoch 4/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.4488 - accuracy: 0.8413\n",
      "Epoch 4: val_loss improved from 0.46884 to 0.46055, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 119s 7ms/step - loss: 0.4488 - accuracy: 0.8413 - val_loss: 0.4605 - val_accuracy: 0.8352\n",
      "Epoch 5/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.4311 - accuracy: 0.8467\n",
      "Epoch 5: val_loss improved from 0.46055 to 0.43658, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.4311 - accuracy: 0.8467 - val_loss: 0.4366 - val_accuracy: 0.8452\n",
      "Epoch 6/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.4175 - accuracy: 0.8494\n",
      "Epoch 6: val_loss improved from 0.43658 to 0.43037, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 119s 7ms/step - loss: 0.4175 - accuracy: 0.8494 - val_loss: 0.4304 - val_accuracy: 0.8461\n",
      "Epoch 7/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.4117 - accuracy: 0.8517\n",
      "Epoch 7: val_loss improved from 0.43037 to 0.42247, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 119s 7ms/step - loss: 0.4116 - accuracy: 0.8517 - val_loss: 0.4225 - val_accuracy: 0.8483\n",
      "Epoch 8/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.4011 - accuracy: 0.8542\n",
      "Epoch 8: val_loss improved from 0.42247 to 0.41640, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.4011 - accuracy: 0.8542 - val_loss: 0.4164 - val_accuracy: 0.8504\n",
      "Epoch 9/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8569\n",
      "Epoch 9: val_loss improved from 0.41640 to 0.41231, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.3916 - accuracy: 0.8569 - val_loss: 0.4123 - val_accuracy: 0.8500\n",
      "Epoch 10/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8575\n",
      "Epoch 10: val_loss improved from 0.41231 to 0.40856, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 117s 7ms/step - loss: 0.3878 - accuracy: 0.8575 - val_loss: 0.4086 - val_accuracy: 0.8532\n",
      "Epoch 11/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8589\n",
      "Epoch 11: val_loss improved from 0.40856 to 0.40011, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.3848 - accuracy: 0.8589 - val_loss: 0.4001 - val_accuracy: 0.8554\n",
      "Epoch 12/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.8607\n",
      "Epoch 12: val_loss did not improve from 0.40011\n",
      "16684/16684 [==============================] - 117s 7ms/step - loss: 0.3783 - accuracy: 0.8607 - val_loss: 0.4066 - val_accuracy: 0.8526\n",
      "Epoch 13/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3752 - accuracy: 0.8613\n",
      "Epoch 13: val_loss improved from 0.40011 to 0.39886, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 106s 6ms/step - loss: 0.3752 - accuracy: 0.8613 - val_loss: 0.3989 - val_accuracy: 0.8550\n",
      "Epoch 14/1000\n",
      "16673/16684 [============================>.] - ETA: 0s - loss: 0.3717 - accuracy: 0.8624\n",
      "Epoch 14: val_loss did not improve from 0.39886\n",
      "16684/16684 [==============================] - 90s 5ms/step - loss: 0.3717 - accuracy: 0.8624 - val_loss: 0.4009 - val_accuracy: 0.8541\n",
      "Epoch 15/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.8630\n",
      "Epoch 15: val_loss did not improve from 0.39886\n",
      "16684/16684 [==============================] - 92s 5ms/step - loss: 0.3686 - accuracy: 0.8630 - val_loss: 0.3994 - val_accuracy: 0.8564\n",
      "Epoch 16/1000\n",
      "16674/16684 [============================>.] - ETA: 0s - loss: 0.3683 - accuracy: 0.8636\n",
      "Epoch 16: val_loss improved from 0.39886 to 0.39227, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3683 - accuracy: 0.8636 - val_loss: 0.3923 - val_accuracy: 0.8574\n",
      "Epoch 17/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3610 - accuracy: 0.8650\n",
      "Epoch 17: val_loss did not improve from 0.39227\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3610 - accuracy: 0.8650 - val_loss: 0.3947 - val_accuracy: 0.8571\n",
      "Epoch 18/1000\n",
      "16675/16684 [============================>.] - ETA: 0s - loss: 0.3600 - accuracy: 0.8655\n",
      "Epoch 18: val_loss improved from 0.39227 to 0.39011, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3600 - accuracy: 0.8655 - val_loss: 0.3901 - val_accuracy: 0.8583\n",
      "Epoch 19/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.8666\n",
      "Epoch 19: val_loss did not improve from 0.39011\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3563 - accuracy: 0.8666 - val_loss: 0.3925 - val_accuracy: 0.8582\n",
      "Epoch 20/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3576 - accuracy: 0.8665\n",
      "Epoch 20: val_loss improved from 0.39011 to 0.38718, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3576 - accuracy: 0.8665 - val_loss: 0.3872 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3541 - accuracy: 0.8673\n",
      "Epoch 21: val_loss improved from 0.38718 to 0.38562, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3541 - accuracy: 0.8673 - val_loss: 0.3856 - val_accuracy: 0.8593\n",
      "Epoch 22/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3516 - accuracy: 0.8679\n",
      "Epoch 22: val_loss did not improve from 0.38562\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3516 - accuracy: 0.8679 - val_loss: 0.3937 - val_accuracy: 0.8571\n",
      "Epoch 23/1000\n",
      "16675/16684 [============================>.] - ETA: 0s - loss: 0.3515 - accuracy: 0.8681\n",
      "Epoch 23: val_loss improved from 0.38562 to 0.38323, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3516 - accuracy: 0.8681 - val_loss: 0.3832 - val_accuracy: 0.8602\n",
      "Epoch 24/1000\n",
      "16674/16684 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.8689\n",
      "Epoch 24: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 90s 5ms/step - loss: 0.3477 - accuracy: 0.8689 - val_loss: 0.3928 - val_accuracy: 0.8579\n",
      "Epoch 25/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.8698\n",
      "Epoch 25: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3455 - accuracy: 0.8698 - val_loss: 0.3856 - val_accuracy: 0.8593\n",
      "Epoch 26/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3404 - accuracy: 0.8713\n",
      "Epoch 26: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3405 - accuracy: 0.8713 - val_loss: 0.3863 - val_accuracy: 0.8589\n",
      "Epoch 27/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3494 - accuracy: 0.8691\n",
      "Epoch 27: val_loss did not improve from 0.38323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16684/16684 [==============================] - 90s 5ms/step - loss: 0.3494 - accuracy: 0.8691 - val_loss: 0.3851 - val_accuracy: 0.8594\n",
      "Epoch 28/1000\n",
      "16673/16684 [============================>.] - ETA: 0s - loss: 0.3408 - accuracy: 0.8713\n",
      "Epoch 28: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3408 - accuracy: 0.8713 - val_loss: 0.3876 - val_accuracy: 0.8578\n",
      "Epoch 29/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3378 - accuracy: 0.8719\n",
      "Epoch 29: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3378 - accuracy: 0.8719 - val_loss: 0.3878 - val_accuracy: 0.8594\n",
      "Epoch 30/1000\n",
      "16673/16684 [============================>.] - ETA: 0s - loss: 0.3421 - accuracy: 0.8708\n",
      "Epoch 30: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3421 - accuracy: 0.8708 - val_loss: 0.3871 - val_accuracy: 0.8603\n",
      "Epoch 31/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3374 - accuracy: 0.8722\n",
      "Epoch 31: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3373 - accuracy: 0.8722 - val_loss: 0.3834 - val_accuracy: 0.8607\n",
      "Epoch 32/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3377 - accuracy: 0.8720\n",
      "Epoch 32: val_loss improved from 0.38323 to 0.38052, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3377 - accuracy: 0.8720 - val_loss: 0.3805 - val_accuracy: 0.8618\n",
      "Epoch 33/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3299 - accuracy: 0.8742\n",
      "Epoch 33: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3299 - accuracy: 0.8742 - val_loss: 0.3911 - val_accuracy: 0.8604\n",
      "Epoch 34/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3330 - accuracy: 0.8733\n",
      "Epoch 34: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3330 - accuracy: 0.8733 - val_loss: 0.3846 - val_accuracy: 0.8603\n",
      "Epoch 35/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3348 - accuracy: 0.8729\n",
      "Epoch 35: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 92s 6ms/step - loss: 0.3348 - accuracy: 0.8729 - val_loss: 0.3821 - val_accuracy: 0.8608\n",
      "Epoch 36/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3348 - accuracy: 0.8733\n",
      "Epoch 36: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 93s 6ms/step - loss: 0.3348 - accuracy: 0.8733 - val_loss: 0.3847 - val_accuracy: 0.8604\n",
      "Epoch 37/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.8755\n",
      "Epoch 37: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 92s 6ms/step - loss: 0.3250 - accuracy: 0.8755 - val_loss: 0.3878 - val_accuracy: 0.8597\n",
      "Epoch 38/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.8743\n",
      "Epoch 38: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 92s 6ms/step - loss: 0.3308 - accuracy: 0.8743 - val_loss: 0.3829 - val_accuracy: 0.8613\n",
      "Epoch 39/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8756\n",
      "Epoch 39: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 90s 5ms/step - loss: 0.3255 - accuracy: 0.8756 - val_loss: 0.3823 - val_accuracy: 0.8608\n",
      "Epoch 40/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8750\n",
      "Epoch 40: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 92s 6ms/step - loss: 0.3295 - accuracy: 0.8750 - val_loss: 0.3856 - val_accuracy: 0.8599\n",
      "Epoch 41/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.8753\n",
      "Epoch 41: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 92s 5ms/step - loss: 0.3263 - accuracy: 0.8753 - val_loss: 0.3886 - val_accuracy: 0.8605\n",
      "Epoch 42/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3256 - accuracy: 0.8757\n",
      "Epoch 42: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3256 - accuracy: 0.8756 - val_loss: 0.3861 - val_accuracy: 0.8586\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "model4 = models.Sequential()\n",
    "model4.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(32,32,1)))\n",
    "model4.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model4.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "model4.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model4.add(layers.Flatten())\n",
    "model4.add(layers.Dense(120, activation='relu'))\n",
    "model4.add(layers.Dense(84, activation='relu'))\n",
    "model4.add(layers.Dense(62, activation='softmax'))\n",
    "\n",
    "early_stopping2 = EarlyStopping(patience = 10)\n",
    "data_name=\"byclass\"\n",
    "type_name=\"LN5\"\n",
    "checkpoint_callback2 = ModelCheckpoint(data_name+\"_\"+type_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#nesteroV 사용해보기\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9,\n",
    "                                    nesterov=True)\n",
    "\n",
    "model4.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "history4=model4.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size), \n",
    "                    epochs=1000,\n",
    "                    callbacks=[early_stopping2, checkpoint_callback2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d5cf2",
   "metadata": {},
   "source": [
    "### adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####LENET-5 정의\n",
    "from tensorflow.keras import layers, models\n",
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(32,32,1)))\n",
    "model3.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model3.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "model3.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(120, activation='relu'))\n",
    "model3.add(layers.Dense(84, activation='relu'))\n",
    "model3.add(layers.Dense(62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab333f",
   "metadata": {
    "id": "37e54f83",
    "outputId": "733f20e2-1be5-4d86-eb76-d771e47b0197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.5739 - accuracy: 0.8085\n",
      "Epoch 1: val_loss improved from inf to 0.45191, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 96s 6ms/step - loss: 0.5738 - accuracy: 0.8085 - val_loss: 0.4519 - val_accuracy: 0.8407\n",
      "Epoch 2/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.4172 - accuracy: 0.8492\n",
      "Epoch 2: val_loss improved from 0.45191 to 0.41200, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 94s 6ms/step - loss: 0.4172 - accuracy: 0.8492 - val_loss: 0.4120 - val_accuracy: 0.8526\n",
      "Epoch 3/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8569\n",
      "Epoch 3: val_loss improved from 0.41200 to 0.40406, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 94s 6ms/step - loss: 0.3893 - accuracy: 0.8569 - val_loss: 0.4041 - val_accuracy: 0.8553\n",
      "Epoch 4/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8599\n",
      "Epoch 4: val_loss did not improve from 0.40406\n",
      "16684/16684 [==============================] - 93s 6ms/step - loss: 0.3799 - accuracy: 0.8599 - val_loss: 0.4090 - val_accuracy: 0.8532\n",
      "Epoch 5/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3669 - accuracy: 0.8633\n",
      "Epoch 5: val_loss improved from 0.40406 to 0.39318, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 94s 6ms/step - loss: 0.3669 - accuracy: 0.8633 - val_loss: 0.3932 - val_accuracy: 0.8584\n",
      "Epoch 6/1000\n",
      "16673/16684 [============================>.] - ETA: 0s - loss: 0.3594 - accuracy: 0.8647\n",
      "Epoch 6: val_loss did not improve from 0.39318\n",
      "16684/16684 [==============================] - 94s 6ms/step - loss: 0.3594 - accuracy: 0.8647 - val_loss: 0.3944 - val_accuracy: 0.8569\n",
      "Epoch 7/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3618 - accuracy: 0.8645\n",
      "Epoch 7: val_loss did not improve from 0.39318\n",
      "16684/16684 [==============================] - 94s 6ms/step - loss: 0.3618 - accuracy: 0.8645 - val_loss: 0.3954 - val_accuracy: 0.8583\n",
      "Epoch 8/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3539 - accuracy: 0.8661\n",
      "Epoch 8: val_loss did not improve from 0.39318\n",
      "16684/16684 [==============================] - 97s 6ms/step - loss: 0.3539 - accuracy: 0.8661 - val_loss: 0.3996 - val_accuracy: 0.8556\n",
      "Epoch 9/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3479 - accuracy: 0.8689\n",
      "Epoch 9: val_loss did not improve from 0.39318\n",
      "16684/16684 [==============================] - 93s 6ms/step - loss: 0.3479 - accuracy: 0.8689 - val_loss: 0.3953 - val_accuracy: 0.8573\n",
      "Epoch 10/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8706\n",
      "Epoch 10: val_loss did not improve from 0.39318\n",
      "16684/16684 [==============================] - 92s 6ms/step - loss: 0.3386 - accuracy: 0.8706 - val_loss: 0.4047 - val_accuracy: 0.8566\n",
      "Epoch 11/1000\n",
      "16673/16684 [============================>.] - ETA: 0s - loss: 0.3485 - accuracy: 0.8685\n",
      "Epoch 11: val_loss did not improve from 0.39318\n",
      "16684/16684 [==============================] - 92s 5ms/step - loss: 0.3485 - accuracy: 0.8685 - val_loss: 0.4087 - val_accuracy: 0.8538\n",
      "Epoch 12/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3359 - accuracy: 0.8715\n",
      "Epoch 12: val_loss did not improve from 0.39318\n",
      "16684/16684 [==============================] - 92s 5ms/step - loss: 0.3359 - accuracy: 0.8715 - val_loss: 0.4067 - val_accuracy: 0.8567\n",
      "Epoch 13/1000\n",
      "16675/16684 [============================>.] - ETA: 0s - loss: 0.3420 - accuracy: 0.8703\n",
      "Epoch 13: val_loss did not improve from 0.39318\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3420 - accuracy: 0.8703 - val_loss: 0.3994 - val_accuracy: 0.8591\n",
      "Epoch 14/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3386 - accuracy: 0.8712\n",
      "Epoch 14: val_loss did not improve from 0.39318\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3386 - accuracy: 0.8712 - val_loss: 0.4060 - val_accuracy: 0.8568\n",
      "Epoch 15/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.8708\n",
      "Epoch 15: val_loss did not improve from 0.39318\n",
      "16684/16684 [==============================] - 94s 6ms/step - loss: 0.3388 - accuracy: 0.8708 - val_loss: 0.4146 - val_accuracy: 0.8543\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience = 10)\n",
    "data_name=\"byclass\"\n",
    "type_name=\"LN5\"\n",
    "checkpoint_callback = ModelCheckpoint(data_name+\"_\"+type_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "history3=model3.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size), \n",
    "                    epochs=1000,\n",
    "                    callbacks=[early_stopping, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d089872",
   "metadata": {},
   "source": [
    "# activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8426d1a4",
   "metadata": {},
   "source": [
    "### selu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf52dc6",
   "metadata": {
    "id": "bbf52dc6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), padding='same',activation='selu', input_shape=(32,32,1)))\n",
    "model2.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model2.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='selu'))\n",
    "model2.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(120, activation='selu'))\n",
    "model2.add(layers.Dense(84, activation='selu'))\n",
    "model2.add(layers.Dense(62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f753a180",
   "metadata": {
    "id": "f753a180"
   },
   "outputs": [],
   "source": [
    "early_stopping_BRN50 = EarlyStopping(patience = 5)\n",
    "data_name=\"byclass\" \n",
    "type_name=\"lenet_selu\"\n",
    "checkpoint_callback_BRN50 = ModelCheckpoint(data_name+\"_\"+type_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddcd801",
   "metadata": {
    "id": "dddcd801",
    "outputId": "07d659f0-b9b0-4051-bc66-bfad5644f30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.9342 - accuracy: 0.7138\n",
      "Epoch 1: val_loss improved from inf to 0.55519, saving model to byclass_lenet_selu.h5\n",
      "16684/16684 [==============================] - 70s 4ms/step - loss: 0.9342 - accuracy: 0.7138 - val_loss: 0.5552 - val_accuracy: 0.8099\n",
      "Epoch 2/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.7674 - accuracy: 0.7551\n",
      "Epoch 2: val_loss improved from 0.55519 to 0.53469, saving model to byclass_lenet_selu.h5\n",
      "16684/16684 [==============================] - 68s 4ms/step - loss: 0.7674 - accuracy: 0.7551 - val_loss: 0.5347 - val_accuracy: 0.8164\n",
      "Epoch 3/1000\n",
      "16671/16684 [============================>.] - ETA: 0s - loss: 0.7373 - accuracy: 0.7640\n",
      "Epoch 3: val_loss improved from 0.53469 to 0.51580, saving model to byclass_lenet_selu.h5\n",
      "16684/16684 [==============================] - 66s 4ms/step - loss: 0.7372 - accuracy: 0.7640 - val_loss: 0.5158 - val_accuracy: 0.8217\n",
      "Epoch 4/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.7231 - accuracy: 0.7683\n",
      "Epoch 4: val_loss improved from 0.51580 to 0.51341, saving model to byclass_lenet_selu.h5\n",
      "16684/16684 [==============================] - 67s 4ms/step - loss: 0.7231 - accuracy: 0.7683 - val_loss: 0.5134 - val_accuracy: 0.8237\n",
      "Epoch 5/1000\n",
      "16667/16684 [============================>.] - ETA: 0s - loss: 0.7124 - accuracy: 0.7717\n",
      "Epoch 5: val_loss improved from 0.51341 to 0.50556, saving model to byclass_lenet_selu.h5\n",
      "16684/16684 [==============================] - 66s 4ms/step - loss: 0.7123 - accuracy: 0.7717 - val_loss: 0.5056 - val_accuracy: 0.8259\n",
      "Epoch 6/1000\n",
      "16674/16684 [============================>.] - ETA: 0s - loss: 0.7018 - accuracy: 0.7739\n",
      "Epoch 6: val_loss improved from 0.50556 to 0.49270, saving model to byclass_lenet_selu.h5\n",
      "16684/16684 [==============================] - 85s 5ms/step - loss: 0.7017 - accuracy: 0.7740 - val_loss: 0.4927 - val_accuracy: 0.8306\n",
      "Epoch 7/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.7767\n",
      "Epoch 7: val_loss did not improve from 0.49270\n",
      "16684/16684 [==============================] - 165s 10ms/step - loss: 0.6932 - accuracy: 0.7767 - val_loss: 0.5080 - val_accuracy: 0.8185\n",
      "Epoch 8/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.6847 - accuracy: 0.7787\n",
      "Epoch 8: val_loss improved from 0.49270 to 0.47782, saving model to byclass_lenet_selu.h5\n",
      "16684/16684 [==============================] - 212s 13ms/step - loss: 0.6846 - accuracy: 0.7787 - val_loss: 0.4778 - val_accuracy: 0.8347\n",
      "Epoch 9/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.6765 - accuracy: 0.7818\n",
      "Epoch 9: val_loss did not improve from 0.47782\n",
      "16684/16684 [==============================] - 212s 13ms/step - loss: 0.6765 - accuracy: 0.7818 - val_loss: 0.4917 - val_accuracy: 0.8313\n",
      "Epoch 10/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.6688 - accuracy: 0.7846\n",
      "Epoch 10: val_loss did not improve from 0.47782\n",
      "16684/16684 [==============================] - 218s 13ms/step - loss: 0.6687 - accuracy: 0.7846 - val_loss: 0.4804 - val_accuracy: 0.8324\n",
      "Epoch 11/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.6610 - accuracy: 0.7861\n",
      "Epoch 11: val_loss did not improve from 0.47782\n",
      "16684/16684 [==============================] - 226s 14ms/step - loss: 0.6610 - accuracy: 0.7861 - val_loss: 0.4837 - val_accuracy: 0.8326\n",
      "Epoch 12/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.6518 - accuracy: 0.7890\n",
      "Epoch 12: val_loss improved from 0.47782 to 0.47165, saving model to byclass_lenet_selu.h5\n",
      "16684/16684 [==============================] - 212s 13ms/step - loss: 0.6519 - accuracy: 0.7890 - val_loss: 0.4717 - val_accuracy: 0.8355\n",
      "Epoch 13/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.6486 - accuracy: 0.7904\n",
      "Epoch 13: val_loss improved from 0.47165 to 0.45630, saving model to byclass_lenet_selu.h5\n",
      "16684/16684 [==============================] - 216s 13ms/step - loss: 0.6486 - accuracy: 0.7904 - val_loss: 0.4563 - val_accuracy: 0.8430\n",
      "Epoch 14/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.6415 - accuracy: 0.7929\n",
      "Epoch 14: val_loss did not improve from 0.45630\n",
      "16684/16684 [==============================] - 211s 13ms/step - loss: 0.6415 - accuracy: 0.7929 - val_loss: 0.4726 - val_accuracy: 0.8389\n",
      "Epoch 15/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.6373 - accuracy: 0.7934\n",
      "Epoch 15: val_loss did not improve from 0.45630\n",
      "16684/16684 [==============================] - 214s 13ms/step - loss: 0.6373 - accuracy: 0.7934 - val_loss: 0.4767 - val_accuracy: 0.8356\n",
      "Epoch 16/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.6327 - accuracy: 0.7944\n",
      "Epoch 16: val_loss did not improve from 0.45630\n",
      "16684/16684 [==============================] - 221s 13ms/step - loss: 0.6326 - accuracy: 0.7944 - val_loss: 0.4848 - val_accuracy: 0.8288\n",
      "Epoch 17/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.6289 - accuracy: 0.7957\n",
      "Epoch 17: val_loss did not improve from 0.45630\n",
      "16684/16684 [==============================] - 213s 13ms/step - loss: 0.6288 - accuracy: 0.7957 - val_loss: 0.4702 - val_accuracy: 0.8362\n",
      "Epoch 18/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.6264 - accuracy: 0.7968\n",
      "Epoch 18: val_loss did not improve from 0.45630\n",
      "16684/16684 [==============================] - 211s 13ms/step - loss: 0.6264 - accuracy: 0.7968 - val_loss: 0.4605 - val_accuracy: 0.8401\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "history=model2.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size), \n",
    "                    epochs=1000,\n",
    "                    callbacks=[early_stopping_BRN50, checkpoint_callback_BRN50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b873ae2c",
   "metadata": {
    "id": "9c894e99"
   },
   "source": [
    "### elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de0373",
   "metadata": {
    "id": "c9de0373"
   },
   "outputs": [],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='elu', input_shape=(32,32,1)))\n",
    "model3.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model3.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='elu'))\n",
    "model3.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(120, activation='elu'))\n",
    "model3.add(layers.Dense(84, activation='elu'))\n",
    "model3.add(layers.Dense(62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1097d",
   "metadata": {
    "id": "beb1097d"
   },
   "outputs": [],
   "source": [
    "early_stopping_BRN50 = EarlyStopping(patience = 5)\n",
    "data_name=\"byclass\" \n",
    "type_name=\"lenet_elu\"\n",
    "checkpoint_callback_BRN50 = ModelCheckpoint(data_name+\"_\"+type_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88609655",
   "metadata": {
    "id": "88609655",
    "outputId": "6e610f29-72c3-4fc4-bc67-2687e339cab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.8126 - accuracy: 0.7477\n",
      "Epoch 1: val_loss improved from inf to 0.47137, saving model to byclass_lenet_elu.h5\n",
      "16684/16684 [==============================] - 215s 13ms/step - loss: 0.8125 - accuracy: 0.7477 - val_loss: 0.4714 - val_accuracy: 0.8372\n",
      "Epoch 2/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.6068 - accuracy: 0.8011\n",
      "Epoch 2: val_loss improved from 0.47137 to 0.45647, saving model to byclass_lenet_elu.h5\n",
      "16684/16684 [==============================] - 220s 13ms/step - loss: 0.6068 - accuracy: 0.8011 - val_loss: 0.4565 - val_accuracy: 0.8418\n",
      "Epoch 3/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.5723 - accuracy: 0.8109\n",
      "Epoch 3: val_loss improved from 0.45647 to 0.45073, saving model to byclass_lenet_elu.h5\n",
      "16684/16684 [==============================] - 219s 13ms/step - loss: 0.5723 - accuracy: 0.8109 - val_loss: 0.4507 - val_accuracy: 0.8447\n",
      "Epoch 4/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.5574 - accuracy: 0.8167\n",
      "Epoch 4: val_loss improved from 0.45073 to 0.44117, saving model to byclass_lenet_elu.h5\n",
      "16684/16684 [==============================] - 213s 13ms/step - loss: 0.5574 - accuracy: 0.8166 - val_loss: 0.4412 - val_accuracy: 0.8457\n",
      "Epoch 5/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.5465 - accuracy: 0.8187\n",
      "Epoch 5: val_loss did not improve from 0.44117\n",
      "16684/16684 [==============================] - 210s 13ms/step - loss: 0.5465 - accuracy: 0.8187 - val_loss: 0.4419 - val_accuracy: 0.8439\n",
      "Epoch 6/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.8215\n",
      "Epoch 6: val_loss improved from 0.44117 to 0.42640, saving model to byclass_lenet_elu.h5\n",
      "16684/16684 [==============================] - 210s 13ms/step - loss: 0.5392 - accuracy: 0.8216 - val_loss: 0.4264 - val_accuracy: 0.8508\n",
      "Epoch 7/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.5367 - accuracy: 0.8228\n",
      "Epoch 7: val_loss did not improve from 0.42640\n",
      "16684/16684 [==============================] - 221s 13ms/step - loss: 0.5366 - accuracy: 0.8228 - val_loss: 0.4344 - val_accuracy: 0.8477\n",
      "Epoch 8/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.5302 - accuracy: 0.8244\n",
      "Epoch 8: val_loss did not improve from 0.42640\n",
      "16684/16684 [==============================] - 213s 13ms/step - loss: 0.5302 - accuracy: 0.8243 - val_loss: 0.4291 - val_accuracy: 0.8507\n",
      "Epoch 9/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.5273 - accuracy: 0.8256\n",
      "Epoch 9: val_loss did not improve from 0.42640\n",
      "16684/16684 [==============================] - 210s 13ms/step - loss: 0.5274 - accuracy: 0.8256 - val_loss: 0.4271 - val_accuracy: 0.8522\n",
      "Epoch 10/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.8262\n",
      "Epoch 10: val_loss did not improve from 0.42640\n",
      "16684/16684 [==============================] - 205s 12ms/step - loss: 0.5243 - accuracy: 0.8262 - val_loss: 0.4432 - val_accuracy: 0.8489\n",
      "Epoch 11/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.8270\n",
      "Epoch 11: val_loss did not improve from 0.42640\n",
      "16684/16684 [==============================] - 209s 13ms/step - loss: 0.5248 - accuracy: 0.8270 - val_loss: 0.4362 - val_accuracy: 0.8504\n"
     ]
    }
   ],
   "source": [
    "model3.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "history3=model3.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size), \n",
    "                    epochs=1000,\n",
    "                    callbacks=[early_stopping_BRN50, checkpoint_callback_BRN50])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
