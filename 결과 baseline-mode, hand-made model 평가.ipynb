{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1950ce",
   "metadata": {},
   "source": [
    "## Hand Made model의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db4a22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  1.2.0\n",
      "TF version:  2.10.1\n",
      "GPU installed:  True\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "print(\"TF version: \", tf.__version__)\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# GPU test\n",
    "print(\"GPU installed: \",tf.test.is_built_with_gpu_support())\n",
    "\n",
    "# To prevent \"CUDNN_STATUS_ALLOC_FAILED\" error with GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b67e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, GlobalAveragePooling2D, MaxPooling2D, Add,  Dense, Conv2D, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d05a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, 5, padding='same', activation='relu', input_shape=[28,28,1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, 2, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Conv2D(128, 2, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad76c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def load_Emist():\n",
    "    X_train=np.load('X_train.npy')\n",
    "    y_train=np.load('y_train.npy')\n",
    "    X_valid=np.load('X_valid.npy')\n",
    "    y_valid=np.load('y_valid.npy')\n",
    "    return X_train, y_train, X_valid, y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c177a6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((533917, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid = load_Emist()\n",
    "X_train.shape,X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3bfce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, batch size 성정\n",
    "train_size=len(X_train)\n",
    "valid_size=len(X_valid)\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac05f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train,[-1,784])\n",
    "X_valid=np.reshape(X_valid,[-1,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5fa66de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.reshape(y_train,[-1,1])\n",
    "y_valid=np.reshape(y_valid,[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76a3fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = np.append(X_train,y_train,axis=1)\n",
    "valid_full = np.append(X_valid,y_valid,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab0392f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    \n",
    "    Emnist_dir = os.path.join(\"datasets\", \"Emnist\")\n",
    "    os.makedirs(Emnist_dir, exist_ok=True)\n",
    "    path_format = os.path.join(Emnist_dir, \"my_{}_{:03d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        try:\n",
    "            with open(part_csv, \"xt\", encoding=\"utf-8\") as f:\n",
    "                if header is not None:\n",
    "                    f.write(header)\n",
    "                    f.write(\"\\n\")\n",
    "                for row_idx in row_indices:\n",
    "                    f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                    f.write(\"\\n\")\n",
    "        except:\n",
    "            continue\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff6e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = save_to_multiple_csv_files(train_full, \"train\")\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_full, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4ef5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[-1]\n",
    "def preprocess_make(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    resized_image = x\n",
    "    final_image = resized_image/255.\n",
    "    return final_image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41d447d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess_make, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d602988",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = csv_reader_dataset(train_filepaths,batch_size=batch_size, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths,batch_size=batch_size, repeat=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df100eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_BRN50 = EarlyStopping(patience = 5)\n",
    "data_name=\"byclass\" \n",
    "type_name=\"make\"\n",
    "hypara=\"adam\"\n",
    "optimizer=tf.keras.optimizers.Adam()\n",
    "checkpoint_callback_BRN50 = ModelCheckpoint(data_name+\"_\"+type_name+\"_\"+hypara+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "605bab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.6228 - accuracy: 0.7982\n",
      "Epoch 1: val_loss improved from inf to 0.40338, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 129s 8ms/step - loss: 0.6228 - accuracy: 0.7982 - val_loss: 0.4034 - val_accuracy: 0.8513 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.4435 - accuracy: 0.8424\n",
      "Epoch 2: val_loss improved from 0.40338 to 0.37463, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 126s 8ms/step - loss: 0.4435 - accuracy: 0.8424 - val_loss: 0.3746 - val_accuracy: 0.8629 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.4082 - accuracy: 0.8524\n",
      "Epoch 3: val_loss improved from 0.37463 to 0.35506, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 127s 8ms/step - loss: 0.4082 - accuracy: 0.8524 - val_loss: 0.3551 - val_accuracy: 0.8689 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.8580\n",
      "Epoch 4: val_loss improved from 0.35506 to 0.34976, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 127s 8ms/step - loss: 0.3899 - accuracy: 0.8580 - val_loss: 0.3498 - val_accuracy: 0.8701 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3778 - accuracy: 0.8611\n",
      "Epoch 5: val_loss improved from 0.34976 to 0.34547, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 127s 8ms/step - loss: 0.3777 - accuracy: 0.8611 - val_loss: 0.3455 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3693 - accuracy: 0.8644\n",
      "Epoch 6: val_loss improved from 0.34547 to 0.34008, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 127s 8ms/step - loss: 0.3693 - accuracy: 0.8644 - val_loss: 0.3401 - val_accuracy: 0.8726 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3617 - accuracy: 0.8662\n",
      "Epoch 7: val_loss improved from 0.34008 to 0.33906, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 127s 8ms/step - loss: 0.3617 - accuracy: 0.8662 - val_loss: 0.3391 - val_accuracy: 0.8744 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3547 - accuracy: 0.8684\n",
      "Epoch 8: val_loss did not improve from 0.33906\n",
      "16684/16684 [==============================] - 127s 8ms/step - loss: 0.3547 - accuracy: 0.8684 - val_loss: 0.3396 - val_accuracy: 0.8744 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3497 - accuracy: 0.8697\n",
      "Epoch 9: val_loss improved from 0.33906 to 0.33666, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 127s 8ms/step - loss: 0.3497 - accuracy: 0.8697 - val_loss: 0.3367 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3447 - accuracy: 0.8713\n",
      "Epoch 10: val_loss improved from 0.33666 to 0.33345, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 128s 8ms/step - loss: 0.3447 - accuracy: 0.8713 - val_loss: 0.3334 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.8725\n",
      "Epoch 11: val_loss did not improve from 0.33345\n",
      "16684/16684 [==============================] - 128s 8ms/step - loss: 0.3411 - accuracy: 0.8725 - val_loss: 0.3368 - val_accuracy: 0.8762 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3373 - accuracy: 0.8735\n",
      "Epoch 12: val_loss did not improve from 0.33345\n",
      "16684/16684 [==============================] - 128s 8ms/step - loss: 0.3373 - accuracy: 0.8735 - val_loss: 0.3345 - val_accuracy: 0.8766 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3321 - accuracy: 0.8753\n",
      "Epoch 13: val_loss improved from 0.33345 to 0.33143, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 128s 8ms/step - loss: 0.3321 - accuracy: 0.8753 - val_loss: 0.3314 - val_accuracy: 0.8777 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3296 - accuracy: 0.8755\n",
      "Epoch 14: val_loss improved from 0.33143 to 0.32900, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 129s 8ms/step - loss: 0.3296 - accuracy: 0.8755 - val_loss: 0.3290 - val_accuracy: 0.8781 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.8763\n",
      "Epoch 15: val_loss did not improve from 0.32900\n",
      "16684/16684 [==============================] - 126s 8ms/step - loss: 0.3266 - accuracy: 0.8763 - val_loss: 0.3369 - val_accuracy: 0.8772 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3227 - accuracy: 0.8781\n",
      "Epoch 16: val_loss did not improve from 0.32900\n",
      "16684/16684 [==============================] - 124s 7ms/step - loss: 0.3227 - accuracy: 0.8781 - val_loss: 0.3332 - val_accuracy: 0.8785 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3199 - accuracy: 0.8784\n",
      "Epoch 17: val_loss did not improve from 0.32900\n",
      "16684/16684 [==============================] - 126s 8ms/step - loss: 0.3199 - accuracy: 0.8784 - val_loss: 0.3395 - val_accuracy: 0.8781 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3012 - accuracy: 0.8846\n",
      "Epoch 18: val_loss improved from 0.32900 to 0.32865, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 127s 8ms/step - loss: 0.3012 - accuracy: 0.8845 - val_loss: 0.3287 - val_accuracy: 0.8798 - lr: 5.0000e-04\n",
      "Epoch 19/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.2952 - accuracy: 0.8860\n",
      "Epoch 19: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 127s 8ms/step - loss: 0.2952 - accuracy: 0.8860 - val_loss: 0.3293 - val_accuracy: 0.8806 - lr: 5.0000e-04\n",
      "Epoch 20/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.8876\n",
      "Epoch 20: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 128s 8ms/step - loss: 0.2916 - accuracy: 0.8876 - val_loss: 0.3303 - val_accuracy: 0.8801 - lr: 5.0000e-04\n",
      "Epoch 21/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.2885 - accuracy: 0.8885\n",
      "Epoch 21: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 127s 8ms/step - loss: 0.2885 - accuracy: 0.8885 - val_loss: 0.3315 - val_accuracy: 0.8799 - lr: 5.0000e-04\n",
      "Epoch 22/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.2793 - accuracy: 0.8911\n",
      "Epoch 22: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 128s 8ms/step - loss: 0.2793 - accuracy: 0.8911 - val_loss: 0.3311 - val_accuracy: 0.8807 - lr: 2.5000e-04\n",
      "Epoch 23/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.8931\n",
      "Epoch 23: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 128s 8ms/step - loss: 0.2750 - accuracy: 0.8931 - val_loss: 0.3314 - val_accuracy: 0.8804 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "lr = keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=3)\n",
    "history=model.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size), \n",
    "                    epochs=1000,\n",
    "                    callbacks=[early_stopping_BRN50, checkpoint_callback_BRN50,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61544d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a26bd240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.6135 - accuracy: 0.8004\n",
      "Epoch 1: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 137s 8ms/step - loss: 0.6134 - accuracy: 0.8004 - val_loss: 0.3975 - val_accuracy: 0.8553 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.4439 - accuracy: 0.8420\n",
      "Epoch 2: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.4439 - accuracy: 0.8420 - val_loss: 0.3726 - val_accuracy: 0.8620 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.4122 - accuracy: 0.8513\n",
      "Epoch 3: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.4122 - accuracy: 0.8513 - val_loss: 0.3644 - val_accuracy: 0.8649 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3967 - accuracy: 0.8560\n",
      "Epoch 4: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3967 - accuracy: 0.8561 - val_loss: 0.3614 - val_accuracy: 0.8642 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8585\n",
      "Epoch 5: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 137s 8ms/step - loss: 0.3878 - accuracy: 0.8585 - val_loss: 0.3534 - val_accuracy: 0.8691 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8609\n",
      "Epoch 6: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3811 - accuracy: 0.8609 - val_loss: 0.3499 - val_accuracy: 0.8702 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3761 - accuracy: 0.8616\n",
      "Epoch 7: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3761 - accuracy: 0.8616 - val_loss: 0.3508 - val_accuracy: 0.8710 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3737 - accuracy: 0.8628\n",
      "Epoch 8: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3738 - accuracy: 0.8628 - val_loss: 0.3510 - val_accuracy: 0.8704 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.8636\n",
      "Epoch 9: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 135s 8ms/step - loss: 0.3709 - accuracy: 0.8636 - val_loss: 0.3407 - val_accuracy: 0.8737 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3683 - accuracy: 0.8641\n",
      "Epoch 10: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3683 - accuracy: 0.8641 - val_loss: 0.3498 - val_accuracy: 0.8728 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3667 - accuracy: 0.8653\n",
      "Epoch 11: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3667 - accuracy: 0.8654 - val_loss: 0.3534 - val_accuracy: 0.8704 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3657 - accuracy: 0.8646\n",
      "Epoch 12: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3657 - accuracy: 0.8646 - val_loss: 0.3478 - val_accuracy: 0.8697 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.8737\n",
      "Epoch 13: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 135s 8ms/step - loss: 0.3388 - accuracy: 0.8737 - val_loss: 0.3316 - val_accuracy: 0.8754 - lr: 5.0000e-04\n",
      "Epoch 14/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3330 - accuracy: 0.8752\n",
      "Epoch 14: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3330 - accuracy: 0.8752 - val_loss: 0.3301 - val_accuracy: 0.8767 - lr: 5.0000e-04\n",
      "Epoch 15/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.8751\n",
      "Epoch 15: val_loss did not improve from 0.32865\n",
      "16684/16684 [==============================] - 135s 8ms/step - loss: 0.3311 - accuracy: 0.8751 - val_loss: 0.3344 - val_accuracy: 0.8766 - lr: 5.0000e-04\n",
      "Epoch 16/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.8747\n",
      "Epoch 16: val_loss improved from 0.32865 to 0.32828, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3325 - accuracy: 0.8747 - val_loss: 0.3283 - val_accuracy: 0.8777 - lr: 5.0000e-04\n",
      "Epoch 17/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3337 - accuracy: 0.8745\n",
      "Epoch 17: val_loss did not improve from 0.32828\n",
      "16684/16684 [==============================] - 138s 8ms/step - loss: 0.3336 - accuracy: 0.8745 - val_loss: 0.3328 - val_accuracy: 0.8757 - lr: 5.0000e-04\n",
      "Epoch 18/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.8742\n",
      "Epoch 18: val_loss did not improve from 0.32828\n",
      "16684/16684 [==============================] - 139s 8ms/step - loss: 0.3347 - accuracy: 0.8742 - val_loss: 0.3345 - val_accuracy: 0.8765 - lr: 5.0000e-04\n",
      "Epoch 19/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3372 - accuracy: 0.8734\n",
      "Epoch 19: val_loss did not improve from 0.32828\n",
      "16684/16684 [==============================] - 140s 8ms/step - loss: 0.3372 - accuracy: 0.8734 - val_loss: 0.3360 - val_accuracy: 0.8755 - lr: 5.0000e-04\n",
      "Epoch 20/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3164 - accuracy: 0.8803\n",
      "Epoch 20: val_loss improved from 0.32828 to 0.32482, saving model to byclass_make_adam.h5\n",
      "16684/16684 [==============================] - 139s 8ms/step - loss: 0.3164 - accuracy: 0.8803 - val_loss: 0.3248 - val_accuracy: 0.8791 - lr: 2.5000e-04\n",
      "Epoch 21/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3120 - accuracy: 0.8815\n",
      "Epoch 21: val_loss did not improve from 0.32482\n",
      "16684/16684 [==============================] - 137s 8ms/step - loss: 0.3120 - accuracy: 0.8815 - val_loss: 0.3298 - val_accuracy: 0.8786 - lr: 2.5000e-04\n",
      "Epoch 22/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.8817\n",
      "Epoch 22: val_loss did not improve from 0.32482\n",
      "16684/16684 [==============================] - 135s 8ms/step - loss: 0.3113 - accuracy: 0.8817 - val_loss: 0.3326 - val_accuracy: 0.8759 - lr: 2.5000e-04\n",
      "Epoch 23/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3125 - accuracy: 0.8810\n",
      "Epoch 23: val_loss did not improve from 0.32482\n",
      "16684/16684 [==============================] - 137s 8ms/step - loss: 0.3126 - accuracy: 0.8810 - val_loss: 0.3295 - val_accuracy: 0.8777 - lr: 2.5000e-04\n",
      "Epoch 24/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.2976 - accuracy: 0.8864\n",
      "Epoch 24: val_loss did not improve from 0.32482\n",
      "16684/16684 [==============================] - 138s 8ms/step - loss: 0.2977 - accuracy: 0.8864 - val_loss: 0.3280 - val_accuracy: 0.8790 - lr: 1.2500e-04\n",
      "Epoch 25/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.2934 - accuracy: 0.8880\n",
      "Epoch 25: val_loss did not improve from 0.32482\n",
      "16684/16684 [==============================] - 135s 8ms/step - loss: 0.2934 - accuracy: 0.8880 - val_loss: 0.3302 - val_accuracy: 0.8789 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, 5, padding='same', activation='relu', input_shape=[28,28,1]))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Conv2D(64, 2, activation='relu', padding='same'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(2))\n",
    "\n",
    "model2.add(Conv2D(128, 2, activation='relu', padding='same'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(2))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(1000, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1000, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(62, activation='softmax'))\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "optimizer = tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate=0.001,\n",
    "                                 beta_1=0.9, beta_2=0.999)\n",
    "model2.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "lr = keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=3)\n",
    "history=model2.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size), \n",
    "                    epochs=1000,\n",
    "                    callbacks=[early_stopping_BRN50, checkpoint_callback_BRN50,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03382c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8013bcb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 28, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 128)       32896     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              6273000   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1000)             4000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 1000)             4000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 62)                62062     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,386,942\n",
      "Trainable params: 7,382,494\n",
      "Non-trainable params: 4,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "922efdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.read_csv('emnist-byclass-train.csv',header=None)\n",
    "x_test=pd.read_csv('emnist-byclass-test.csv',header=None)\n",
    "\n",
    "def data_load(data_type_train,data_type_test):\n",
    "    x_train =data_type_train.iloc[:, 1:].values.astype('float32')\n",
    "    y_train = data_type_train.iloc[:, 0].values\n",
    "    x_test = data_type_test.iloc[:, 1:].values.astype('float32')\n",
    "    y_test = data_type_test.iloc[:, 0].values\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28)\n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n",
    "x_train,y_train,x_test,y_test=data_load(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "007c698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "787cf41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116323, 28, 28, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b13a5d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116323,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "414514eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "50c34e3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 5s 1ms/step - loss: 2303.8103 - accuracy: 0.0604\n"
     ]
    }
   ],
   "source": [
    "y_true= y_test\n",
    "y_pred= model2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf30959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_c=np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6115e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "confu=confusion_matrix(y_true, y_pred_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19586872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27333590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(con_mat, labels, title='Confusion Matrix', cmap=plt.cm.get_cmap('Blues'), normalize=False):\n",
    "    plt.imshow(con_mat, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    marks = np.arange(len(labels))\n",
    "    nlabels = []\n",
    "    for k in range(len(con_mat)):\n",
    "        n = sum(con_mat[k])\n",
    "        nlabel = '{0}(n={1})'.format(labels[k],n)\n",
    "        nlabels.append(nlabel)\n",
    "    plt.xticks(marks, labels)\n",
    "    plt.yticks(marks, nlabels)\n",
    "\n",
    "    thresh = con_mat.max() / 2.\n",
    "    if normalize:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, '{0}%'.format(con_mat[i, j] * 100 / n), horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    else:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, con_mat[i, j], horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ddd19630",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= np.arange(62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6fdcc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "408d00d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2,\n",
       " 7,\n",
       " 10,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 30,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 42,\n",
       " 48,\n",
       " 52}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_pred_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84c367f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 16, 16, 35, 22, 16, 16, 16, 16, 15, 35, 17, 35, 34, 35, 16, 16,\n",
       "       32, 15, 16, 16, 34, 34, 20, 16, 16, 35, 16, 16, 22, 32, 15, 15, 18,\n",
       "       16, 16, 16, 16, 16, 15, 16, 32, 10, 16, 16, 18, 16, 16, 30, 16, 16,\n",
       "       16, 15, 15, 16, 16, 32, 34, 16, 15, 20, 16, 13, 16, 17, 35, 15, 20,\n",
       "       16, 16, 16, 16, 16, 15, 32, 16, 16, 22, 20, 16, 32, 34, 16, 35, 17,\n",
       "       16, 16, 16, 18, 16, 15, 15, 18, 16, 16, 16, 16, 35, 32, 16, 16, 16,\n",
       "       15, 16, 22, 16, 35, 22, 16, 15, 16, 16, 32, 16, 20, 34, 22, 16, 18,\n",
       "       15, 16, 16, 16, 16, 16, 16, 16, 32, 35, 16, 16, 16, 15, 15, 35, 35,\n",
       "       16, 16, 16, 16, 22, 16, 16, 16, 18, 15, 35, 16, 16, 16, 35, 15, 16,\n",
       "       16, 18, 18, 16, 17, 32, 16, 15, 13, 15, 16, 35, 16, 16, 16, 16, 16,\n",
       "       18, 16, 10, 22, 10, 18, 16, 34, 16, 16, 16, 16, 16, 34, 16, 30, 16,\n",
       "       22, 22, 10, 15, 16, 16, 22, 32, 10, 35, 16, 16, 16, 22, 16, 16, 16,\n",
       "       16, 16, 16, 15, 16, 22, 16, 16, 15, 15, 16, 16, 16, 30, 16, 15, 16,\n",
       "       16, 15, 16, 16, 16, 16, 32, 16, 22, 16, 10, 16, 22, 18, 16, 16, 21,\n",
       "       18, 16, 16, 22, 35, 32, 16, 18, 22, 15, 22, 16, 18, 16, 16, 16, 16,\n",
       "       16, 32, 15, 35, 18, 22, 16, 16, 16, 10, 22, 16, 16, 32, 16, 16, 16,\n",
       "       16, 16, 16, 32, 16, 15, 16, 16, 22, 16, 16, 22, 16, 16, 15, 16, 16,\n",
       "       16, 16, 18, 15, 16, 16, 22, 16, 22, 15, 15, 16, 18, 16, 10, 15, 15,\n",
       "       16, 15, 16, 16, 16, 16, 18, 18, 22, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 16, 16, 16, 35, 16, 15, 22, 15, 16, 16, 34, 16, 34, 16,\n",
       "       16, 16, 16, 16, 35, 32, 20, 16, 15, 15, 16, 16, 16, 10, 16, 22, 16,\n",
       "       16, 35, 17, 22, 35, 22, 10, 15, 16, 16, 16, 15, 10, 22, 16, 16, 22,\n",
       "       16, 16, 16, 15, 16, 16, 15, 16, 15, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 35, 16, 16, 35, 16, 15, 16, 16, 16, 16, 16, 35, 16, 22, 16, 34,\n",
       "       16, 16, 16, 16, 35, 15, 16, 22, 16, 16, 16, 16, 35, 16, 32, 16, 35,\n",
       "       21, 16, 16, 35, 16, 16, 16, 15, 17, 35, 22, 16, 35, 16, 35, 16, 16,\n",
       "       35, 18, 16, 32, 16, 16, 16, 15, 16, 22, 16, 16, 15, 22, 16, 16, 16,\n",
       "       16, 18, 22, 18, 15, 18, 22, 16, 17, 16, 16, 20, 18, 34, 16, 34, 16,\n",
       "       16, 15, 16, 16, 15, 16, 34, 22, 18, 16, 16, 16, 18, 35, 18, 16, 16,\n",
       "       22, 16, 16, 16, 10, 22, 16, 34, 16, 16, 18, 17, 16, 15, 17, 16, 16,\n",
       "       16, 22, 22, 35, 16, 15, 16, 35, 16, 18, 16, 17, 18, 22, 16, 16, 16,\n",
       "       16, 16, 13, 16, 18, 16, 16, 16, 22, 16, 35, 16, 16, 16, 16, 15, 22,\n",
       "       20, 16, 16, 16, 16, 35, 16, 22, 16, 16, 22, 22, 16, 22, 35, 35, 16,\n",
       "       35, 16, 16, 34, 17, 16, 16, 16, 18, 15, 32, 16, 16, 35, 16, 32, 16,\n",
       "       16, 35, 16, 15, 16, 16, 15, 13, 32, 17, 15, 16, 34, 35, 22, 16, 35,\n",
       "       16, 15, 16, 22, 13], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_c[:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d44424f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.models.load_model(\"byclass_make_adam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "22f3819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filepaths = save_to_multiple_csv_files(valid_full, \"test\")\n",
    "test_set = csv_reader_dataset(test_filepaths,batch_size=batch_size, repeat=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404c568",
   "metadata": {},
   "source": [
    "## hand-made model의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68ba38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  86053/Unknown - 298s 3ms/step - loss: 0.3266 - accuracy: 0.8783"
     ]
    }
   ],
   "source": [
    "y_true= y_test\n",
    "y_pred= model3.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confu, labels=y_test, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a420a",
   "metadata": {},
   "source": [
    "## Baseline model 정의 및 훈련과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca874a",
   "metadata": {
    "id": "e9ca874a"
   },
   "outputs": [],
   "source": [
    "#####LENET-5 정의\n",
    "from tensorflow.keras import layers, models\n",
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(32,32,1)))\n",
    "model3.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model3.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "model3.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(120, activation='relu'))\n",
    "model3.add(layers.Dense(84, activation='relu'))\n",
    "model3.add(layers.Dense(62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e54f83",
   "metadata": {
    "id": "37e54f83",
    "outputId": "022e4c36-07a8-413f-e64c-2bd0f4feb5a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.5777 - accuracy: 0.8077\n",
      "Epoch 1: val_loss improved from inf to 0.45623, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 134s 8ms/step - loss: 0.5776 - accuracy: 0.8077 - val_loss: 0.4562 - val_accuracy: 0.8379\n",
      "Epoch 2/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.4259 - accuracy: 0.8468\n",
      "Epoch 2: val_loss improved from 0.45623 to 0.41630, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 123s 7ms/step - loss: 0.4259 - accuracy: 0.8468 - val_loss: 0.4163 - val_accuracy: 0.8510\n",
      "Epoch 3/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3995 - accuracy: 0.8544\n",
      "Epoch 3: val_loss improved from 0.41630 to 0.41325, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3996 - accuracy: 0.8544 - val_loss: 0.4133 - val_accuracy: 0.8513\n",
      "Epoch 4/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3918 - accuracy: 0.8561\n",
      "Epoch 4: val_loss improved from 0.41325 to 0.39889, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3918 - accuracy: 0.8561 - val_loss: 0.3989 - val_accuracy: 0.8538\n",
      "Epoch 5/1000\n",
      "16675/16684 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8592\n",
      "Epoch 5: val_loss improved from 0.39889 to 0.39835, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 105s 6ms/step - loss: 0.3815 - accuracy: 0.8592 - val_loss: 0.3983 - val_accuracy: 0.8547\n",
      "Epoch 6/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3721 - accuracy: 0.8612\n",
      "Epoch 6: val_loss improved from 0.39835 to 0.39834, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 102s 6ms/step - loss: 0.3721 - accuracy: 0.8612 - val_loss: 0.3983 - val_accuracy: 0.8561\n",
      "Epoch 7/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.8623\n",
      "Epoch 7: val_loss improved from 0.39834 to 0.38756, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 104s 6ms/step - loss: 0.3709 - accuracy: 0.8623 - val_loss: 0.3876 - val_accuracy: 0.8590\n",
      "Epoch 8/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.8620\n",
      "Epoch 8: val_loss did not improve from 0.38756\n",
      "16684/16684 [==============================] - 104s 6ms/step - loss: 0.3695 - accuracy: 0.8620 - val_loss: 0.3907 - val_accuracy: 0.8567\n",
      "Epoch 9/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.8633\n",
      "Epoch 9: val_loss improved from 0.38756 to 0.38511, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3656 - accuracy: 0.8633 - val_loss: 0.3851 - val_accuracy: 0.8598\n",
      "Epoch 10/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3511 - accuracy: 0.8669\n",
      "Epoch 10: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3511 - accuracy: 0.8669 - val_loss: 0.3942 - val_accuracy: 0.8586\n",
      "Epoch 11/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3629 - accuracy: 0.8639\n",
      "Epoch 11: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3628 - accuracy: 0.8639 - val_loss: 0.3904 - val_accuracy: 0.8586\n",
      "Epoch 12/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.8651\n",
      "Epoch 12: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3592 - accuracy: 0.8651 - val_loss: 0.3873 - val_accuracy: 0.8589\n",
      "Epoch 13/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3600 - accuracy: 0.8646\n",
      "Epoch 13: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3601 - accuracy: 0.8646 - val_loss: 0.3925 - val_accuracy: 0.8577\n",
      "Epoch 14/1000\n",
      "16675/16684 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.8675\n",
      "Epoch 14: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3510 - accuracy: 0.8675 - val_loss: 0.3949 - val_accuracy: 0.8581\n",
      "Epoch 15/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8665\n",
      "Epoch 15: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3532 - accuracy: 0.8665 - val_loss: 0.3862 - val_accuracy: 0.8582\n",
      "Epoch 16/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3546 - accuracy: 0.8663\n",
      "Epoch 16: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3546 - accuracy: 0.8663 - val_loss: 0.3913 - val_accuracy: 0.8567\n",
      "Epoch 17/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3558 - accuracy: 0.8657\n",
      "Epoch 17: val_loss did not improve from 0.38511\n",
      "16684/16684 [==============================] - 102s 6ms/step - loss: 0.3558 - accuracy: 0.8657 - val_loss: 0.3895 - val_accuracy: 0.8576\n",
      "Epoch 18/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3495 - accuracy: 0.8678\n",
      "Epoch 18: val_loss improved from 0.38511 to 0.38315, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 104s 6ms/step - loss: 0.3495 - accuracy: 0.8678 - val_loss: 0.3832 - val_accuracy: 0.8600\n",
      "Epoch 19/1000\n",
      "16674/16684 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.8685\n",
      "Epoch 19: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 103s 6ms/step - loss: 0.3477 - accuracy: 0.8685 - val_loss: 0.3910 - val_accuracy: 0.8582\n",
      "Epoch 20/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8679\n",
      "Epoch 20: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 104s 6ms/step - loss: 0.3488 - accuracy: 0.8679 - val_loss: 0.3848 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3518 - accuracy: 0.8673\n",
      "Epoch 21: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 134s 8ms/step - loss: 0.3518 - accuracy: 0.8673 - val_loss: 0.3873 - val_accuracy: 0.8580\n",
      "Epoch 22/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.8683\n",
      "Epoch 22: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3482 - accuracy: 0.8683 - val_loss: 0.3840 - val_accuracy: 0.8605\n",
      "Epoch 23/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3467 - accuracy: 0.8688\n",
      "Epoch 23: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 137s 8ms/step - loss: 0.3468 - accuracy: 0.8688 - val_loss: 0.3900 - val_accuracy: 0.8573\n",
      "Epoch 24/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3495 - accuracy: 0.8678\n",
      "Epoch 24: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3495 - accuracy: 0.8678 - val_loss: 0.3872 - val_accuracy: 0.8598\n",
      "Epoch 25/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3489 - accuracy: 0.8680\n",
      "Epoch 25: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 137s 8ms/step - loss: 0.3489 - accuracy: 0.8680 - val_loss: 0.3850 - val_accuracy: 0.8598\n",
      "Epoch 26/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3440 - accuracy: 0.8694\n",
      "Epoch 26: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 135s 8ms/step - loss: 0.3440 - accuracy: 0.8694 - val_loss: 0.3910 - val_accuracy: 0.8576\n",
      "Epoch 27/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3424 - accuracy: 0.8697\n",
      "Epoch 27: val_loss did not improve from 0.38315\n",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3424 - accuracy: 0.8697 - val_loss: 0.3864 - val_accuracy: 0.8595\n",
      "Epoch 28/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3450 - accuracy: 0.8690\n",
      "Epoch 28: val_loss did not improve from 0.38315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "16684/16684 [==============================] - 136s 8ms/step - loss: 0.3450 - accuracy: 0.8690 - val_loss: 0.3858 - val_accuracy: 0.8590\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience = 10)\n",
    "data_name=\"byclass\"\n",
    "type_name=\"LN5\"\n",
    "checkpoint_callback = ModelCheckpoint(data_name+\"_\"+type_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate=0.001,\n",
    "                                 beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model3.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "history3=model3.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size), \n",
    "                    epochs=1000,\n",
    "                    callbacks=[early_stopping, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2cc308",
   "metadata": {
    "id": "5a2cc308",
    "outputId": "426a3f33-2fa1-45c0-95c4-dff109fad0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.8855 - accuracy: 0.7368\n",
      "Epoch 1: val_loss improved from inf to 0.57336, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.8854 - accuracy: 0.7368 - val_loss: 0.5734 - val_accuracy: 0.8080\n",
      "Epoch 2/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.5216 - accuracy: 0.8220\n",
      "Epoch 2: val_loss improved from 0.57336 to 0.50539, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.5216 - accuracy: 0.8220 - val_loss: 0.5054 - val_accuracy: 0.8243\n",
      "Epoch 3/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.4761 - accuracy: 0.8338\n",
      "Epoch 3: val_loss improved from 0.50539 to 0.46884, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.4762 - accuracy: 0.8338 - val_loss: 0.4688 - val_accuracy: 0.8362\n",
      "Epoch 4/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.4488 - accuracy: 0.8413\n",
      "Epoch 4: val_loss improved from 0.46884 to 0.46055, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 119s 7ms/step - loss: 0.4488 - accuracy: 0.8413 - val_loss: 0.4605 - val_accuracy: 0.8352\n",
      "Epoch 5/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.4311 - accuracy: 0.8467\n",
      "Epoch 5: val_loss improved from 0.46055 to 0.43658, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.4311 - accuracy: 0.8467 - val_loss: 0.4366 - val_accuracy: 0.8452\n",
      "Epoch 6/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.4175 - accuracy: 0.8494\n",
      "Epoch 6: val_loss improved from 0.43658 to 0.43037, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 119s 7ms/step - loss: 0.4175 - accuracy: 0.8494 - val_loss: 0.4304 - val_accuracy: 0.8461\n",
      "Epoch 7/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.4117 - accuracy: 0.8517\n",
      "Epoch 7: val_loss improved from 0.43037 to 0.42247, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 119s 7ms/step - loss: 0.4116 - accuracy: 0.8517 - val_loss: 0.4225 - val_accuracy: 0.8483\n",
      "Epoch 8/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.4011 - accuracy: 0.8542\n",
      "Epoch 8: val_loss improved from 0.42247 to 0.41640, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.4011 - accuracy: 0.8542 - val_loss: 0.4164 - val_accuracy: 0.8504\n",
      "Epoch 9/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8569\n",
      "Epoch 9: val_loss improved from 0.41640 to 0.41231, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.3916 - accuracy: 0.8569 - val_loss: 0.4123 - val_accuracy: 0.8500\n",
      "Epoch 10/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8575\n",
      "Epoch 10: val_loss improved from 0.41231 to 0.40856, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 117s 7ms/step - loss: 0.3878 - accuracy: 0.8575 - val_loss: 0.4086 - val_accuracy: 0.8532\n",
      "Epoch 11/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8589\n",
      "Epoch 11: val_loss improved from 0.40856 to 0.40011, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 118s 7ms/step - loss: 0.3848 - accuracy: 0.8589 - val_loss: 0.4001 - val_accuracy: 0.8554\n",
      "Epoch 12/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.8607\n",
      "Epoch 12: val_loss did not improve from 0.40011\n",
      "16684/16684 [==============================] - 117s 7ms/step - loss: 0.3783 - accuracy: 0.8607 - val_loss: 0.4066 - val_accuracy: 0.8526\n",
      "Epoch 13/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3752 - accuracy: 0.8613\n",
      "Epoch 13: val_loss improved from 0.40011 to 0.39886, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 106s 6ms/step - loss: 0.3752 - accuracy: 0.8613 - val_loss: 0.3989 - val_accuracy: 0.8550\n",
      "Epoch 14/1000\n",
      "16673/16684 [============================>.] - ETA: 0s - loss: 0.3717 - accuracy: 0.8624\n",
      "Epoch 14: val_loss did not improve from 0.39886\n",
      "16684/16684 [==============================] - 90s 5ms/step - loss: 0.3717 - accuracy: 0.8624 - val_loss: 0.4009 - val_accuracy: 0.8541\n",
      "Epoch 15/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.8630\n",
      "Epoch 15: val_loss did not improve from 0.39886\n",
      "16684/16684 [==============================] - 92s 5ms/step - loss: 0.3686 - accuracy: 0.8630 - val_loss: 0.3994 - val_accuracy: 0.8564\n",
      "Epoch 16/1000\n",
      "16674/16684 [============================>.] - ETA: 0s - loss: 0.3683 - accuracy: 0.8636\n",
      "Epoch 16: val_loss improved from 0.39886 to 0.39227, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3683 - accuracy: 0.8636 - val_loss: 0.3923 - val_accuracy: 0.8574\n",
      "Epoch 17/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3610 - accuracy: 0.8650\n",
      "Epoch 17: val_loss did not improve from 0.39227\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3610 - accuracy: 0.8650 - val_loss: 0.3947 - val_accuracy: 0.8571\n",
      "Epoch 18/1000\n",
      "16675/16684 [============================>.] - ETA: 0s - loss: 0.3600 - accuracy: 0.8655\n",
      "Epoch 18: val_loss improved from 0.39227 to 0.39011, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3600 - accuracy: 0.8655 - val_loss: 0.3901 - val_accuracy: 0.8583\n",
      "Epoch 19/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.8666\n",
      "Epoch 19: val_loss did not improve from 0.39011\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3563 - accuracy: 0.8666 - val_loss: 0.3925 - val_accuracy: 0.8582\n",
      "Epoch 20/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3576 - accuracy: 0.8665\n",
      "Epoch 20: val_loss improved from 0.39011 to 0.38718, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3576 - accuracy: 0.8665 - val_loss: 0.3872 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3541 - accuracy: 0.8673\n",
      "Epoch 21: val_loss improved from 0.38718 to 0.38562, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3541 - accuracy: 0.8673 - val_loss: 0.3856 - val_accuracy: 0.8593\n",
      "Epoch 22/1000\n",
      "16681/16684 [============================>.] - ETA: 0s - loss: 0.3516 - accuracy: 0.8679\n",
      "Epoch 22: val_loss did not improve from 0.38562\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3516 - accuracy: 0.8679 - val_loss: 0.3937 - val_accuracy: 0.8571\n",
      "Epoch 23/1000\n",
      "16675/16684 [============================>.] - ETA: 0s - loss: 0.3515 - accuracy: 0.8681\n",
      "Epoch 23: val_loss improved from 0.38562 to 0.38323, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3516 - accuracy: 0.8681 - val_loss: 0.3832 - val_accuracy: 0.8602\n",
      "Epoch 24/1000\n",
      "16674/16684 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.8689\n",
      "Epoch 24: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 90s 5ms/step - loss: 0.3477 - accuracy: 0.8689 - val_loss: 0.3928 - val_accuracy: 0.8579\n",
      "Epoch 25/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.8698\n",
      "Epoch 25: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3455 - accuracy: 0.8698 - val_loss: 0.3856 - val_accuracy: 0.8593\n",
      "Epoch 26/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3404 - accuracy: 0.8713\n",
      "Epoch 26: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3405 - accuracy: 0.8713 - val_loss: 0.3863 - val_accuracy: 0.8589\n",
      "Epoch 27/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3494 - accuracy: 0.8691\n",
      "Epoch 27: val_loss did not improve from 0.38323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16684/16684 [==============================] - 90s 5ms/step - loss: 0.3494 - accuracy: 0.8691 - val_loss: 0.3851 - val_accuracy: 0.8594\n",
      "Epoch 28/1000\n",
      "16673/16684 [============================>.] - ETA: 0s - loss: 0.3408 - accuracy: 0.8713\n",
      "Epoch 28: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3408 - accuracy: 0.8713 - val_loss: 0.3876 - val_accuracy: 0.8578\n",
      "Epoch 29/1000\n",
      "16677/16684 [============================>.] - ETA: 0s - loss: 0.3378 - accuracy: 0.8719\n",
      "Epoch 29: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3378 - accuracy: 0.8719 - val_loss: 0.3878 - val_accuracy: 0.8594\n",
      "Epoch 30/1000\n",
      "16673/16684 [============================>.] - ETA: 0s - loss: 0.3421 - accuracy: 0.8708\n",
      "Epoch 30: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3421 - accuracy: 0.8708 - val_loss: 0.3871 - val_accuracy: 0.8603\n",
      "Epoch 31/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3374 - accuracy: 0.8722\n",
      "Epoch 31: val_loss did not improve from 0.38323\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3373 - accuracy: 0.8722 - val_loss: 0.3834 - val_accuracy: 0.8607\n",
      "Epoch 32/1000\n",
      "16676/16684 [============================>.] - ETA: 0s - loss: 0.3377 - accuracy: 0.8720\n",
      "Epoch 32: val_loss improved from 0.38323 to 0.38052, saving model to byclass_LN5.h5\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3377 - accuracy: 0.8720 - val_loss: 0.3805 - val_accuracy: 0.8618\n",
      "Epoch 33/1000\n",
      "16684/16684 [==============================] - ETA: 0s - loss: 0.3299 - accuracy: 0.8742\n",
      "Epoch 33: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 89s 5ms/step - loss: 0.3299 - accuracy: 0.8742 - val_loss: 0.3911 - val_accuracy: 0.8604\n",
      "Epoch 34/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3330 - accuracy: 0.8733\n",
      "Epoch 34: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3330 - accuracy: 0.8733 - val_loss: 0.3846 - val_accuracy: 0.8603\n",
      "Epoch 35/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3348 - accuracy: 0.8729\n",
      "Epoch 35: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 92s 6ms/step - loss: 0.3348 - accuracy: 0.8729 - val_loss: 0.3821 - val_accuracy: 0.8608\n",
      "Epoch 36/1000\n",
      "16682/16684 [============================>.] - ETA: 0s - loss: 0.3348 - accuracy: 0.8733\n",
      "Epoch 36: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 93s 6ms/step - loss: 0.3348 - accuracy: 0.8733 - val_loss: 0.3847 - val_accuracy: 0.8604\n",
      "Epoch 37/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.8755\n",
      "Epoch 37: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 92s 6ms/step - loss: 0.3250 - accuracy: 0.8755 - val_loss: 0.3878 - val_accuracy: 0.8597\n",
      "Epoch 38/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.8743\n",
      "Epoch 38: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 92s 6ms/step - loss: 0.3308 - accuracy: 0.8743 - val_loss: 0.3829 - val_accuracy: 0.8613\n",
      "Epoch 39/1000\n",
      "16683/16684 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8756\n",
      "Epoch 39: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 90s 5ms/step - loss: 0.3255 - accuracy: 0.8756 - val_loss: 0.3823 - val_accuracy: 0.8608\n",
      "Epoch 40/1000\n",
      "16679/16684 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8750\n",
      "Epoch 40: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 92s 6ms/step - loss: 0.3295 - accuracy: 0.8750 - val_loss: 0.3856 - val_accuracy: 0.8599\n",
      "Epoch 41/1000\n",
      "16678/16684 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.8753\n",
      "Epoch 41: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 92s 5ms/step - loss: 0.3263 - accuracy: 0.8753 - val_loss: 0.3886 - val_accuracy: 0.8605\n",
      "Epoch 42/1000\n",
      "16680/16684 [============================>.] - ETA: 0s - loss: 0.3256 - accuracy: 0.8757\n",
      "Epoch 42: val_loss did not improve from 0.38052\n",
      "16684/16684 [==============================] - 91s 5ms/step - loss: 0.3256 - accuracy: 0.8756 - val_loss: 0.3861 - val_accuracy: 0.8586\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "model4 = models.Sequential()\n",
    "model4.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(32,32,1)))\n",
    "model4.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model4.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "model4.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model4.add(layers.Flatten())\n",
    "model4.add(layers.Dense(120, activation='relu'))\n",
    "model4.add(layers.Dense(84, activation='relu'))\n",
    "model4.add(layers.Dense(62, activation='softmax'))\n",
    "\n",
    "early_stopping2 = EarlyStopping(patience = 10)\n",
    "data_name=\"byclass\"\n",
    "type_name=\"LN5\"\n",
    "checkpoint_callback2 = ModelCheckpoint(data_name+\"_\"+type_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#nesteroV 사용해보기\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9,\n",
    "                                    nesterov=True)\n",
    "\n",
    "model4.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "history4=model4.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size), \n",
    "                    epochs=1000,\n",
    "                    callbacks=[early_stopping2, checkpoint_callback2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b970d19f",
   "metadata": {
    "id": "b970d19f"
   },
   "outputs": [],
   "source": [
    "\n",
    "model3 = tf.keras.models.load_model(\"byclass_LN5.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9HnWryvbjaoH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HnWryvbjaoH",
    "outputId": "f22f40b1-3f46-4271-d28a-e414629f82bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 14, 14, 6)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,126\n",
      "Trainable params: 66,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "hO11kxnJeohe",
   "metadata": {
    "id": "hO11kxnJeohe"
   },
   "outputs": [],
   "source": [
    "\n",
    "hand1=pd.read_csv('emnist_handwriting_20180565_psm.csv',header=None)\n",
    "hand2=pd.read_csv('emnist_handwriting_20230615_psm.csv',header=None)\n",
    "hand3=pd.read_csv('emnist_handwriting_20180611_psm.csv',header=None)\n",
    "hand4=pd.read_csv('ha.csv',header=None)\n",
    "xh_test=np.concatenate((hand1,hand2,hand3,hand4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "LmmqqOOGeojj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmmqqOOGeojj",
    "outputId": "31c0aff2-8fe7-4872-b148-81ea3d588901"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2560, 785)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xh_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "s7okvoYjeolN",
   "metadata": {
    "id": "s7okvoYjeolN"
   },
   "outputs": [],
   "source": [
    "def data_load_test(data_type_test):\n",
    "    x_test = data_type_test.iloc[:, 1:].values.astype('float32')\n",
    "    y_test = data_type_test.iloc[:, 0].values\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28)\n",
    "    return x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "lpdk2xbGfwEV",
   "metadata": {
    "id": "lpdk2xbGfwEV"
   },
   "outputs": [],
   "source": [
    "x_test,y_test=data_load_test(pd.DataFrame(aaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "krf0mGN7gM1R",
   "metadata": {
    "id": "krf0mGN7gM1R"
   },
   "outputs": [],
   "source": [
    "test_size=len(x_test)\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "rCAFdxY9gM3G",
   "metadata": {
    "id": "rCAFdxY9gM3G"
   },
   "outputs": [],
   "source": [
    "x_test=np.reshape(x_test,[-1,784])\n",
    "y_test=np.reshape(y_test,[-1,1])\n",
    "test_full = np.append(x_test,y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "wsyxynnRg5_v",
   "metadata": {
    "id": "wsyxynnRg5_v"
   },
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    \n",
    "    Emnist_dir = os.path.join(\"datasets\", \"Emnist\")\n",
    "    os.makedirs(Emnist_dir, exist_ok=True)\n",
    "    path_format = os.path.join(Emnist_dir, \"my_{}_{:03d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        try:\n",
    "            with open(part_csv, \"xt\", encoding=\"utf-8\") as f:\n",
    "                if header is not None:\n",
    "                    f.write(header)\n",
    "                    f.write(\"\\n\")\n",
    "                for row_idx in row_indices:\n",
    "                    f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                    f.write(\"\\n\")\n",
    "        except:\n",
    "            continue\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b3o6Yv1fg6CT",
   "metadata": {
    "id": "b3o6Yv1fg6CT"
   },
   "outputs": [],
   "source": [
    "test_filepaths = save_to_multiple_csv_files(test_full, \"test\")\n",
    "n_inputs = x_test.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "Kvx4XPwufFi3",
   "metadata": {
    "id": "Kvx4XPwufFi3"
   },
   "outputs": [],
   "source": [
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    resized_image = tf.image.resize(x, [32, 32])\n",
    "    \n",
    "    final_image = resized_image/255\n",
    "    \n",
    "    return final_image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "GHp07d9_fFlL",
   "metadata": {
    "id": "GHp07d9_fFlL"
   },
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "Dxcgz6eQf_4C",
   "metadata": {
    "id": "Dxcgz6eQf_4C"
   },
   "outputs": [],
   "source": [
    "test_set = csv_reader_dataset(test_filepaths,batch_size=batch_size, repeat=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2711e28b",
   "metadata": {},
   "source": [
    "## Baseline 모델의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "VeYMJct_xUdX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeYMJct_xUdX",
    "outputId": "0a6486ee-b789-4e50-83cb-ce07a7cb3b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 5ms/step - loss: 0.3723 - accuracy: 0.8460\n",
      "[0.372334678152693, 0.846015789]\n"
     ]
    }
   ],
   "source": [
    "model3.evaluate(test_set,steps=len(x_test)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e04195",
   "metadata": {},
   "outputs": [],
   "source": [
    "###찾기쉽게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c394f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###마지막"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
